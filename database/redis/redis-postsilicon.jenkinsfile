pipeline {
    agent {
        label "vmware-190"
    }
    environment {
        server =  "$params.server"
    }
    //前提条件： 节点需要在Jenkins上托管，可连接
	stages {
	    stage('reinstall') {
	        steps {
	            script {
	                try {
	                    node(server) {
	                        // 检查是否是CentOS8系统，如果不是则抛出异常
                            sh 'cat /etc/os-release | grep "CentOS Stream 8"'
                        }
	                } catch (Exception e) {
	                    //异常处理： 重装CentOS8
	                    node("vmware-190") {
                            dir("scripts") {
                                git credentialsId: 'Gitlab', url: 'git@gitlab.hj-micro.com:appsoftware/scripts.git'
                            }
                            sh '''
                                python3 scripts/bios/bios.py --ability reinstall --server_ip ${server} --reboot true --attributes 'CentOS8'
                                echo "Waiting for reboot"
                                sleep 1500s
                                for i in {1..10}
                                do {
                                    ping ${server} -c 3 && break 
                                } || {
                                    sleep 120s 
                                }
                                done
                            '''
                            // cobbler也用相同的业务IP，异常情况下，还在装机就Ping通然后往下
                        }
                    }
                }
            }
        }
        stage('kernel') {
            steps {
                script {
                    try {
                        node(server) {
                            sh '''
                            if [[ "$(uname -a | grep 5.10)" == "" ]]
                            then
                                cd /
                                bash install_kernel.sh
                                exit 1
                            fi
                            '''
                            //节点重启自己会有流程异常，抛出exit 1到异常处理中有其他机器启动重启流程
                        }
                    } catch (Exception e) {
                        node("vmware-190") {
                            dir("scripts") {
                                git credentialsId: 'Gitlab', url: 'git@gitlab.hj-micro.com:appsoftware/scripts.git'
                            }
                            sh '''
                            python3 scripts/bios/bios.py --ability reboot --server_ip ${server} --reboot true --attributes '{}'
                            sleep 300s
                            for i in {1..10}
                                do {
                                    ping ${server} -c 3 && break 
                                } || {
                                    sleep 120s 
                                }
                                done
                            '''
                        }
                    }
                }
            }
        }
        stage('EnvPrepare') {
            steps {
                node(server) {
                    sh '''
                     echo always > /sys/kernel/mm/transparent_hugepage/enabled
                     systemctl start irqbalance
                     systemctl stop firewalld
                   '''
                }
            }
        }
        stage('Build&Install') {
            steps {
                node(server) {
                    dir("redis") {
                        git branch: '6.2', url: 'https://gitee.com/mirrors/redis.git'
                    }
                    sh '''
                        cd redis
                        git checkout -b v6.2.6 6.2.6
                        make -j 8
                        make install
                    '''
                } 
            }
        }
        stage('UnitTest') {
            steps {
                node(server) {
                    sh '''
                        cd redis
                        make test
                    '''
                }
            }
        }
        stage('DefaultConfig') {
            steps {
                node(server) {
                    sh 'redis-server --daemonize yes'
                    sh '''
                        PID=$(pidof redis-server)
                        mkdir -p /sys/fs/cgroup/cpu/mygroup
                        echo 1000000 > /sys/fs/cgroup/cpu/mygroup/cpu.cfs_period_us
                        echo 2000000 > /sys/fs/cgroup/cpu/mygroup/cpu.cfs_quota_us
                        echo ${PID} > /sys/fs/cgroup/cpu/mygroup/tasks
                    '''
                    sh '''
                        cd /usr/local/bin/
                        ./redis-benchmark -q -t SET -n 1000000 --threads 2
                        ./redis-benchmark -q -t GET -n 1000000 --threads 2
                        ./redis-benchmark -q -t INCR -n 1000000 --threads 2
                        ./redis-benchmark -q -t LPUSH -n 1000000 --threads 2
                        ./redis-benchmark -q -t RPUSH -n 1000000 --threads 2
                        ./redis-benchmark -q -t LPOP -n 1000000 --threads 2
                        ./redis-benchmark -q -t RPOP -n 1000000 --threads 2
                        ./redis-benchmark -q -t LRANGE_100 -n 1000000 --threads 2
                        ./redis-benchmark -q -t LRANGE_300 -n 1000000 --threads 2
                        ./redis-benchmark -q -t LRANGE_500 -n 1000000 --threads 2
                        ./redis-benchmark -q -t LRANGE_600 -n 1000000 --threads 2
                        ./redis-benchmark -q -t SADD -n 1000000 --threads 2
                        ./redis-benchmark -q -t HSET -n 1000000 --threads 2
                        ./redis-benchmark -q -t ZADD -n 1000000 --threads 2
                        ./redis-benchmark -q -t ZPOPMIN -n 1000000 --threads 2
                        ./redis-benchmark -q -t MSET -n 1000000 --threads 2
                        ./redis-benchmark -q -t SET -P 50 -n 1000000 --threads 2
                        ./redis-benchmark -q -t SET -P 100 -n 1000000 --threads 2
                        ./redis-benchmark -q -t SET -P 150 -n 1000000 --threads 2
                        ./redis-benchmark -q -t SET -P 200 -n 1000000 --threads 2
                        ./redis-cli shutdown
                    '''
                }
            }
        }
        // 以下测试用例默认配置均为Naqu双路服务器，128c*2，4 NUMA node
        stage('SingleNUMA') {
            steps {
                node(server) {
                    sh 'numactl -C 1,2 -m 0 redis-server redis/redis.conf --daemonize yes'
                    sh '''
                        cd /usr/local/bin/
                        numactl -C 64-95 ./redis-benchmark -q -t SET -n 1000000 --threads 2
                        numactl -C 64-95 ./redis-benchmark -q -t GET -n 1000000 --threads 2
                        ./redis-cli shutdown
                    '''
                }
            }
        }
        stage('CrossNUMA') {
            steps {
                node(server) {
                    sh 'numactl -C 1,2 -m 1 redis-server redis/redis.conf --daemonize yes'
                    sh '''
                     cd /usr/local/bin/
                     numactl -C 64-95 ./redis-benchmark -q -t SET -n 1000000 --threads 2
                     numactl -C 64-95 ./redis-benchmark -q -t GET -n 1000000 --threads 2
                     ./redis-cli shutdown
                    '''
                }
            }
        }
        stage('CrossSocket') {
            steps {
                node(server) {
                    sh 'numactl -C 1,2 -m 2 redis-server redis/redis.conf --daemonize yes'
                    sh '''
                        cd /usr/local/bin/
                        numactl -C 64-95 ./redis-benchmark -q -t SET -n 1000000 --threads 2
                        numactl -C 64-95 ./redis-benchmark -q -t GET -n 1000000 --threads 2
                        ./redis-cli shutdown
                    '''
                }
            }
        }
        stage('Cleanup') {
            steps {
                node(server) {
                    sh '''
                        rm -rf redis/
                        rm -f dump.rdb
                    '''
                }
            }
        }
    }
    post {
        success {
            node(server) {
                // 从标准输出log获取各测试用例性能，归档至数据库;
                // 默认用户根目录下已存在MySQL客户端程序mysql和Jenkins客户端程序jenkins-cli.jar;
                sh '''
                    # 业务常量和复用变量定义
                    DB_HOST="10.1.180.190"
                    DB_USER="root"
                    DB_PASS="mysql"
                    DB_NAME="redis"
                    LOG_URL="\\"${BUILD_URL}console\\""
                    SQL_INSERT=""
                    LOG_FILTER=""
                    RPS=-1
                    P50=-1
                    
                    # 获取std log
                    export JAVA_HOME=/usr/lib/jvm/java-11
                    export PATH=$JAVA_HOME/bin:$PATH
                    wget -q http://10.1.180.188:8080/jnlpJars/jenkins-cli.jar
                    java -jar jenkins-cli.jar -s http://10.1.180.188:8080/ console ${JOB_NAME} > redis.log
                    wget http://10.1.180.190/database/mysql/mysql

                    # UT结果入库
                    if grep -q 'All tests passed without errors!' redis.log; then
                        SQL_INSERT="INSERT INTO naqu (test_case_id, RPS, P50, log_url) VALUES (1, 1, 0, ${LOG_URL})"
                    else  
                        SQL_INSERT="INSERT INTO naqu (test_case_id, RPS, P50, log_url) VALUES (1, 0, 0, ${LOG_URL})"
                    fi 
                    ./mysql -h$DB_HOST -u$DB_USER -p$DB_PASS $DB_NAME -e \"${SQL_INSERT}\"
                    
                    # SET性能入库
                    LOG_FILTER=$(grep 'SET:' redis.log | grep 'p50' | head -n 1)
                    RPS=$(echo $LOG_FILTER | awk '{print $(NF-5)}')
                    P50=$(echo $LOG_FILTER | sed -n 's/.*p50=\\([0-9.]*\\).*/\\1/p')
                    SQL_INSERT="INSERT INTO naqu (test_case_id, RPS, P50, log_url) VALUES (2, ${RPS}, ${P50}, ${LOG_URL})"
                    ./mysql -h$DB_HOST -u$DB_USER -p$DB_PASS $DB_NAME -e \"$SQL_INSERT\"

                    # GET性能入库
                    LOG_FILTER=$(grep 'GET:' redis.log | grep 'p50' | head -n 1)
                    RPS=$(echo $LOG_FILTER | awk '{print $(NF-5)}')
                    P50=$(echo $LOG_FILTER | sed -n 's/.*p50=\\([0-9.]*\\).*/\\1/p')
                    SQL_INSERT="INSERT INTO naqu (test_case_id, RPS, P50, log_url) VALUES (3, ${RPS}, ${P50}, ${LOG_URL})"
                    ./mysql -h$DB_HOST -u$DB_USER -p$DB_PASS $DB_NAME -e \"$SQL_INSERT\"

                    # INCR性能入库
                    LOG_FILTER=$(grep 'INCR:' redis.log | grep 'p50')
                    RPS=$(echo $LOG_FILTER | awk '{print $(NF-5)}')
                    P50=$(echo $LOG_FILTER | sed -n 's/.*p50=\\([0-9.]*\\).*/\\1/p')
                    SQL_INSERT="INSERT INTO naqu (test_case_id, RPS, P50, log_url) VALUES (4, ${RPS}, ${P50}, ${LOG_URL})"
                    ./mysql -h$DB_HOST -u$DB_USER -p$DB_PASS $DB_NAME -e \"$SQL_INSERT\"

                    # LPUSH性能入库
                    LOG_FILTER=$(grep 'LPUSH:' redis.log | grep 'p50')
                    RPS=$(echo $LOG_FILTER | awk '{print $(NF-5)}')
                    P50=$(echo $LOG_FILTER | sed -n 's/.*p50=\\([0-9.]*\\).*/\\1/p')
                    SQL_INSERT="INSERT INTO naqu (test_case_id, RPS, P50, log_url) VALUES (5, ${RPS}, ${P50}, ${LOG_URL})"
                    ./mysql -h$DB_HOST -u$DB_USER -p$DB_PASS $DB_NAME -e \"$SQL_INSERT\"

                    # RPUSH性能入库
                    LOG_FILTER=$(grep 'RPUSH:' redis.log | grep 'p50')
                    RPS=$(echo $LOG_FILTER | awk '{print $(NF-5)}')
                    P50=$(echo $LOG_FILTER | sed -n 's/.*p50=\\([0-9.]*\\).*/\\1/p')
                    SQL_INSERT="INSERT INTO naqu (test_case_id, RPS, P50, log_url) VALUES (6, ${RPS}, ${P50}, ${LOG_URL})"
                    ./mysql -h$DB_HOST -u$DB_USER -p$DB_PASS $DB_NAME -e \"$SQL_INSERT\"

                    # LPOP性能入库
                    LOG_FILTER=$(grep 'LPOP:' redis.log | grep 'p50')
                    RPS=$(echo $LOG_FILTER | awk '{print $(NF-5)}')
                    P50=$(echo $LOG_FILTER | sed -n 's/.*p50=\\([0-9.]*\\).*/\\1/p')
                    SQL_INSERT="INSERT INTO naqu (test_case_id, RPS, P50, log_url) VALUES (7, ${RPS}, ${P50}, ${LOG_URL})"
                    ./mysql -h$DB_HOST -u$DB_USER -p$DB_PASS $DB_NAME -e \"$SQL_INSERT\"

                    # RPOP性能入库
                    LOG_FILTER=$(grep 'RPOP:' redis.log | grep 'p50')
                    RPS=$(echo $LOG_FILTER | awk '{print $(NF-5)}')
                    P50=$(echo $LOG_FILTER | sed -n 's/.*p50=\\([0-9.]*\\).*/\\1/p')
                    SQL_INSERT="INSERT INTO naqu (test_case_id, RPS, P50, log_url) VALUES (8, ${RPS}, ${P50}, ${LOG_URL})"
                    ./mysql -h$DB_HOST -u$DB_USER -p$DB_PASS $DB_NAME -e \"$SQL_INSERT"

                    # LRANGE_100性能入库
                    LOG_FILTER=$(grep 'LRANGE_100 (first 100 elements):' redis.log | grep 'p50')
                    RPS=$(echo $LOG_FILTER | awk '{print $(NF-5)}')
                    P50=$(echo $LOG_FILTER | sed -n 's/.*p50=\\([0-9.]*\\).*/\\1/p')
                    SQL_INSERT="INSERT INTO naqu (test_case_id, RPS, P50, log_url) VALUES (9, ${RPS}, ${P50}, ${LOG_URL})"
                    ./mysql -h$DB_HOST -u$DB_USER -p$DB_PASS $DB_NAME -e \"$SQL_INSERT\"

                    # LRANGE_300性能入库
                    LOG_FILTER=$(grep 'LRANGE_300 (first 300 elements):' redis.log | grep 'p50')
                    RPS=$(echo $LOG_FILTER | awk '{print $(NF-5)}')
                    P50=$(echo $LOG_FILTER | sed -n 's/.*p50=\\([0-9.]*\\).*/\\1/p')
                    SQL_INSERT="INSERT INTO naqu (test_case_id, RPS, P50, log_url) VALUES (10, ${RPS}, ${P50}, ${LOG_URL})"
                    ./mysql -h$DB_HOST -u$DB_USER -p$DB_PASS $DB_NAME -e \"$SQL_INSERT\"

                    # LRANGE_500性能入库
                    LOG_FILTER=$(grep 'LRANGE_500 (first 500 elements):' redis.log | grep 'p50')
                    RPS=$(echo $LOG_FILTER | awk '{print $(NF-5)}')
                    P50=$(echo $LOG_FILTER | sed -n 's/.*p50=\\([0-9.]*\\).*/\\1/p')
                    SQL_INSERT="INSERT INTO naqu (test_case_id, RPS, P50, log_url) VALUES (11, ${RPS}, ${P50}, ${LOG_URL})"
                    ./mysql -h$DB_HOST -u$DB_USER -p$DB_PASS $DB_NAME -e \"$SQL_INSERT\"

                    # LRANGE_600性能入库
                    LOG_FILTER=$(grep 'LRANGE_600 (first 600 elements):' redis.log | grep 'p50')
                    RPS=$(echo $LOG_FILTER | awk '{print $(NF-5)}')
                    P50=$(echo $LOG_FILTER | sed -n 's/.*p50=\\([0-9.]*\\).*/\\1/p')
                    SQL_INSERT="INSERT INTO naqu (test_case_id, RPS, P50, log_url) VALUES (12, ${RPS}, ${P50}, ${LOG_URL})"
                    ./mysql -h$DB_HOST -u$DB_USER -p$DB_PASS $DB_NAME -e \"$SQL_INSERT\"

                    # SADD性能入库
                    LOG_FILTER=$(grep 'SADD:' redis.log | grep 'p50')
                    RPS=$(echo $LOG_FILTER | awk '{print $(NF-5)}')
                    P50=$(echo $LOG_FILTER | sed -n 's/.*p50=\\([0-9.]*\\).*/\\1/p')
                    SQL_INSERT="INSERT INTO naqu (test_case_id, RPS, P50, log_url) VALUES (13, ${RPS}, ${P50}, ${LOG_URL})"
                    ./mysql -h$DB_HOST -u$DB_USER -p$DB_PASS $DB_NAME -e \"$SQL_INSERT\"


                    # HSET性能入库
                    LOG_FILTER=$(grep 'HSET:' redis.log | grep 'p50')
                    RPS=$(echo $LOG_FILTER | awk '{print $(NF-5)}')
                    P50=$(echo $LOG_FILTER | sed -n 's/.*p50=\\([0-9.]*\\).*/\\1/p')
                    SQL_INSERT="INSERT INTO naqu (test_case_id, RPS, P50, log_url) VALUES (14, ${RPS}, ${P50}, ${LOG_URL})"
                    ./mysql -h$DB_HOST -u$DB_USER -p$DB_PASS $DB_NAME -e \"$SQL_INSERT\"

                    # ZADD性能入库
                    LOG_FILTER=$(grep 'ZADD:' redis.log | grep 'p50')
                    RPS=$(echo $LOG_FILTER | awk '{print $(NF-5)}')
                    P50=$(echo $LOG_FILTER | sed -n 's/.*p50=\\([0-9.]*\\).*/\\1/p')
                    SQL_INSERT="INSERT INTO naqu (test_case_id, RPS, P50, log_url) VALUES (15, ${RPS}, ${P50}, ${LOG_URL})"
                    ./mysql -h$DB_HOST -u$DB_USER -p$DB_PASS $DB_NAME -e \"$SQL_INSERT\"

                    # ZPOPMIN性能入库
                    LOG_FILTER=$(grep 'ZPOPMIN:' redis.log | grep 'p50')
                    RPS=$(echo $LOG_FILTER | awk '{print $(NF-5)}')
                    P50=$(echo $LOG_FILTER | sed -n 's/.*p50=\\([0-9.]*\\).*/\\1/p')
                    SQL_INSERT="INSERT INTO naqu (test_case_id, RPS, P50, log_url) VALUES (16, ${RPS}, ${P50}, ${LOG_URL})"
                    ./mysql -h$DB_HOST -u$DB_USER -p$DB_PASS $DB_NAME -e \"$SQL_INSERT\"

                    # MSET性能入库
                    LOG_FILTER=$(grep 'MSET (10 keys):' redis.log | grep 'p50')
                    RPS=$(echo $LOG_FILTER | awk '{print $(NF-5)}')
                    P50=$(echo $LOG_FILTER | sed -n 's/.*p50=\\([0-9.]*\\).*/\\1/p')
                    SQL_INSERT="INSERT INTO naqu (test_case_id, RPS, P50, log_url) VALUES (17, ${RPS}, ${P50}, ${LOG_URL})"
                    ./mysql -h$DB_HOST -u$DB_USER -p$DB_PASS $DB_NAME -e \"$SQL_INSERT\"

                    # 50 pipeline性能入库
                    LOG_FILTER=$(grep 'SET:' redis.log | grep 'p50' | awk 'NR==3')
                    RPS=$(echo $LOG_FILTER | awk '{print $(NF-5)}')
                    P50=$(echo $LOG_FILTER | sed -n 's/.*p50=\\([0-9.]*\\).*/\\1/p')
                    SQL_INSERT="INSERT INTO naqu (test_case_id, RPS, P50, log_url) VALUES (18, ${RPS}, ${P50}, ${LOG_URL})"
                    ./mysql -h$DB_HOST -u$DB_USER -p$DB_PASS $DB_NAME -e \"$SQL_INSERT\"

                    # 100 pipeline性能入库
                    LOG_FILTER=$(grep 'SET:' redis.log | grep 'p50' | awk 'NR==4')
                    RPS=$(echo $LOG_FILTER | awk '{print $(NF-5)}')
                    P50=$(echo $LOG_FILTER | sed -n 's/.*p50=\\([0-9.]*\\).*/\\1/p')
                    SQL_INSERT="INSERT INTO naqu (test_case_id, RPS, P50, log_url) VALUES (19, ${RPS}, ${P50}, ${LOG_URL})"
                    ./mysql -h$DB_HOST -u$DB_USER -p$DB_PASS $DB_NAME -e \"$SQL_INSERT\"

                    # 150 pipeline性能入库
                    LOG_FILTER=$(grep 'SET:' redis.log | grep 'p50' | awk 'NR==5')
                    RPS=$(echo $LOG_FILTER | awk '{print $(NF-5)}')
                    P50=$(echo $LOG_FILTER | sed -n 's/.*p50=\\([0-9.]*\\).*/\\1/p')
                    SQL_INSERT="INSERT INTO naqu (test_case_id, RPS, P50, log_url) VALUES (20, ${RPS}, ${P50}, ${LOG_URL})"
                    ./mysql -h$DB_HOST -u$DB_USER -p$DB_PASS $DB_NAME -e \"$SQL_INSERT\"

                    # 200 pipeline性能入库
                    LOG_FILTER=$(grep 'SET:' redis.log | grep 'p50' | awk 'NR==6')
                    RPS=$(echo $LOG_FILTER | awk '{print $(NF-5)}')
                    P50=$(echo $LOG_FILTER | sed -n 's/.*p50=\\([0-9.]*\\).*/\\1/p')
                    SQL_INSERT="INSERT INTO naqu (test_case_id, RPS, P50, log_url) VALUES (21, ${RPS}, ${P50}, ${LOG_URL})"
                    ./mysql -h$DB_HOST -u$DB_USER -p$DB_PASS $DB_NAME -e \"$SQL_INSERT\"

                    # 单NUMA SET性能入库
                    LOG_FILTER=$(grep 'SET:' redis.log | grep 'p50' | awk 'NR==7')
                    RPS=$(echo $LOG_FILTER | awk '{print $(NF-5)}')
                    P50=$(echo $LOG_FILTER | sed -n 's/.*p50=\\([0-9.]*\\).*/\\1/p')
                    SQL_INSERT="INSERT INTO naqu (test_case_id, RPS, P50, log_url) VALUES (22, ${RPS}, ${P50}, ${LOG_URL})"
                    ./mysql -h$DB_HOST -u$DB_USER -p$DB_PASS $DB_NAME -e \"$SQL_INSERT\"

                    # 单NUMA GET性能入库
                    LOG_FILTER=$(grep 'GET:' redis.log | grep 'p50' | awk 'NR==2')
                    RPS=$(echo $LOG_FILTER | awk '{print $(NF-5)}')
                    P50=$(echo $LOG_FILTER | sed -n 's/.*p50=\\([0-9.]*\\).*/\\1/p')
                    SQL_INSERT="INSERT INTO naqu (test_case_id, RPS, P50, log_url) VALUES (23, ${RPS}, ${P50}, ${LOG_URL})"
                    ./mysql -h$DB_HOST -u$DB_USER -p$DB_PASS $DB_NAME -e \"$SQL_INSERT\"

                    # 跨NUMA SET性能入库
                    LOG_FILTER=$(grep 'SET:' redis.log | grep 'p50' | awk 'NR==8')
                    RPS=$(echo $LOG_FILTER | awk '{print $(NF-5)}')
                    P50=$(echo $LOG_FILTER | sed -n 's/.*p50=\\([0-9.]*\\).*/\\1/p')
                    SQL_INSERT="INSERT INTO naqu (test_case_id, RPS, P50, log_url) VALUES (24, ${RPS}, ${P50}, ${LOG_URL})"
                    ./mysql -h$DB_HOST -u$DB_USER -p$DB_PASS $DB_NAME -e \"$SQL_INSERT\"

                    # 跨NUMA GET性能入库
                    LOG_FILTER=$(grep 'GET:' redis.log | grep 'p50' | awk 'NR==3')
                    RPS=$(echo $LOG_FILTER | awk '{print $(NF-5)}')
                    P50=$(echo $LOG_FILTER | sed -n 's/.*p50=\\([0-9.]*\\).*/\\1/p')
                    SQL_INSERT="INSERT INTO naqu (test_case_id, RPS, P50, log_url) VALUES (25, ${RPS}, ${P50}, ${LOG_URL})"
                    ./mysql -h$DB_HOST -u$DB_USER -p$DB_PASS $DB_NAME -e \"$SQL_INSERT\"

                    # 跨Socket SET性能入库
                    LOG_FILTER=$(grep 'SET:' redis.log | grep 'p50' | awk 'NR==9')
                    RPS=$(echo $LOG_FILTER | awk '{print $(NF-5)}')
                    P50=$(echo $LOG_FILTER | sed -n 's/.*p50=\\([0-9.]*\\).*/\\1/p')
                    SQL_INSERT="INSERT INTO naqu (test_case_id, RPS, P50, log_url) VALUES (26, ${RPS}, ${P50}, ${LOG_URL})"
                    ./mysql -h$DB_HOST -u$DB_USER -p$DB_PASS $DB_NAME -e \"$SQL_INSERT\"

                    # 跨Socket GET性能入库
                    LOG_FILTER=$(grep 'GET:' redis.log | grep 'p50' | awk 'NR==4')
                    RPS=$(echo $LOG_FILTER | awk '{print $(NF-5)}')
                    P50=$(echo $LOG_FILTER | sed -n 's/.*p50=\\([0-9.]*\\).*/\\1/p')
                    SQL_INSERT="INSERT INTO naqu (test_case_id, RPS, P50, log_url) VALUES (27, ${RPS}, ${P50}, ${LOG_URL})"
                    ./mysql -h$DB_HOST -u$DB_USER -p$DB_PASS $DB_NAME -e \"$SQL_INSERT\"

                    # 关闭连接
                    ./mysql -h$DB_HOST -u$DB_USER -p$DB_PASS $DB_NAME -e "exit"
                    
                    # 清理缓存log和jar包
                    rm -f redis.log jenkins-cli.jar
                '''
            }
        }
    }
}
